<!doctype html>
<html lang="en">

<head>
  <style>
	.highlight {
		position: absolute;
		border: 3px solid red;
		opacity: 0;
		transition: opacity 0.5s ease-in-out;
	}
	
	.highlight.show {
		opacity: 1;
	}
	
	.container {
		position: relative;
		display: inline-block;
	}
	
	.highlight-1 { width: 150px; height: 150px; top: 50px; left: 100px; }
	.highlight-2 { width: 200px; height: 200px; top: 200px; left: 300px; }
	/* Add more highlight styles as needed */
  </style>

  <script src="highlight.js"></script>
	  
  <meta charset="utf-8">

  <!-- Title of page (as it will appear in search results) -->
  <title>Intro to LLM</title>

  <meta name="apple-mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<link rel="stylesheet" href="https://ubc-library-rc.github.io/reveal-ubc/css/reset.css">
	<link rel="stylesheet" href="https://ubc-library-rc.github.io/reveal-ubc/css/reveal.css">
	<link rel="stylesheet" href="https://ubc-library-rc.github.io/reveal-ubc/css/ubc.css" id="theme">

	<!-- Theme used for syntax highlighting of code -->
	<link rel="stylesheet" href="https://ubc-library-rc.github.io/reveal-ubc/lib/css/monokai.css">

	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement( 'link' );
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match( /print-pdf/gi ) ? 'https://ubc-library-rc.github.io/reveal-ubc/css/print/pdf.css' : 'https://ubc-library-rc.github.io/reveal-ubc/css/print/paper.css';
		document.getElementsByTagName( 'head' )[0].appendChild( link );
	</script>

	<!--[if lt IE 9]>
	<script src="lib/js/html5shiv.js"></script>
	<![endif]-->
</head>

<body>

<div class="reveal">

	<div class="slides">

		<section>
			<h3>Introduction to Large Language Models (LLMs)</h3>
			https://ubc-library-rc.github.io/llm/
			<aside class="notes">
				<p>
					
				While we are getting started, I would love to know what brings you to this workshop.
				Those were some interesting answers.    

				</p>
			</aside>
		</section>

		<section style="text-align: left;">
			<h3>Land Acknowledgement</h3>
			<p>UBC Vancouver is located on the traditional, ancestral, and unceded territory of the xʷməθkʷəy̓əm (Musqueam) peoples.</p>
			<aside class="notes">
				<p>
				But before going into more details I would like to begin by acknowledging that I .
				</p>
			</aside>
		</section>


		<section>
			Use the Zoom toolbar to engage
			<img  data-src="../content/zoom-figures/zoom_toolbar.png" alt="The Zoom toolbar">
			<div class="fragment">
				<p style="font-size: smaller"><em>Participants</em> window</p>
				<img data-src="../content/zoom-figures/participants_window_menu.png" alt="The participants menu">
			</div>
			<aside class="notes">
				<p>
				Active participation makes the session so much fun and gives me and your peers much more energy. We are
				all sitting in our offices with little sound. Your voices and perspectives enlivens the session. We encourage
				you to engage with each other and instructors.

				The participants window lists everyone in the session and click the icons at the bottom to communicate with
				the instructors.

				You can also use the Chat windows to comment or ask questions at any time. It is also a good place to share
				problems with your audio connection.
				</p>
			</aside>
		</section>

		<section data-background="#e6f7ff">
			<h3>Learning Objectives</h3>
			<ul>
				<li class="fragment fade-in-then-semi-out"> Understand architecture and working of LLM</li>
				<li class="fragment fade-in-then-semi-out"> Fine tune pre-trained LLM model to customize for a sample dataset</li>
				<li class="fragment fade-in-then-semi-out"> Understand various aspects of using LLMs for research.</li>
			</ul>
			<aside class="notes">
				<p>
				So, to touch various viewpoints of LLMs, we have the following learning objectives for this workshop:
				</p>
			</aside>
		</section>

		<section data-background="#e6f7ff">
			<h3>Pre-workshop setup</h3>
			<ul>
				<li class="fragment fade-in-then-semi-out">GOOGLE COLAB <a href="https://colab.research.google.com/">(https://colab.research.google.com/)</a></li>
			</ul>
			<aside class="notes">
				<p>
					For hands-on exercises, we will use [Python](https://www.python.org/) on [Jupyter Notebooks](https://jupyter.org/). You don’t need to have Python installed. Please make sure that you have a [UBC Syzygy](https://ubc.syzygy.ca/) or a [Google Colaboratory](https://colab.research.google.com/) account. (You will need a CWL login to access Syzygy.)

					hands-on exercises, programming tools and libraries, such as [Python] and [scikit-learn] prior familiarity with Python programming is recommended, we do not study the codes in detail
				</p>
			</aside>
		</section>


		<section data-background="#e6f7ff">
			<h3>Background</h3>
			<img height="400px" src="background.png">
			<aside class="notes">
				<p>
					Before diving into LLMs, let’s quickly go over some basics that make LLMs, LLMs. 
					Neural Networks: A type of machine learning process, called deep learning, that uses interconnected nodes or neurons in a layered structure that resembles the human brain.
					RNN: a type of neural network designed to work with sequence data. Explore LSTMs and GRUs, two RNN variants that are capable of learning long-term dependencies.

					Natural Language Proceesing: A branch of AI—concerned with giving computers the ability to understand text and spoken words in much the same way human beings can.
					Text Preprocessing: Tokenization (splitting text into words or sentences), stemming (reducing words to their root form), lemmatization (similar to stemming but considers the context), stop word removal.
					Feature Extraction Techniques: Converting text data into a format that can be understood by machine learning algorithms. Key methods include Bag-of-words (BoW), Term Frequency-Inverse Document Frequency (TF-IDF), and n-grams.
					Word Embeddings: Word embeddings are a type of word representation that allows words with similar meanings to have similar representations. Key methods include Word2Vec, GloVe, and FastText.
				</p>
			</aside>
		</section>



		<section data-background="#e6f7ff">
			<h3>What are Large Language Models?</h3>
			<ul>
				<li class="fragment fade-in-then-semi-out">Large Language Models (LLMs) are artificial intelligence systems designed to understand and generate human-like language.</li>
				<li class="fragment fade-in-then-semi-out">LLMs are fundamental to natural language processing, powering applications like chatbots, language translation, and content generation.</li>
			</ul>
			<aside class="notes">
				<p>
					LLMs: Read out the definition and explain. 
				</p>
			</aside>
		</section>

		<section data-background="#e6f7ff">
			<h3>Let's pretend to be LLM (..or just a human)</h3>
			<ul>
				<li class="fragment fade-in-then-semi-out">Excerise 1: The cat sat on a _____. </li>
				<li class="fragment fade-in-then-semi-out" style="color: blue;">LLM says: "The cat sat on a sunny windowsill, basking in the warmth of the afternoon sun."</li>
				<li class="fragment fade-in-then-semi-out">Excerise 2: Tell me a two sentence story of a dog named Pluto</li>
				<li class="fragment fade-in-then-semi-out" style="color: blue;">LLM says: "Pluto, a spirited golden retriever with a heart full of curiosity, embarked on a solo adventure through the bustling city streets. With a wagging tail and a friendly demeanor, he charmed everyone..."</li>
			</ul>
			<aside class="notes">
				<p>
					
				</p>
			</aside>
		</section>

		<section data-background="#e6f7ff">
			<h3>Let's pretend to be LLM (..or a smart human)</h3>
			<ul>
				<li class="fragment fade-in-then-semi-out">Excerise 3: Write a html code of a ..... </li>
				<li class="fragment fade-in-then-semi-out" style="color: blue;">LLM writes the whole code in 10 seconds.</li>
			</ul>
		
				<aside class="notes">
				<p>
					Previous one was an easier task, but how about this one? 
					Even for such tasks, that needs a lot of time for us to do. LLMs can do it in few seconds. 
					May not be the best job as a human. But quicker. A person using it still need domain knowledge to understand the code and fix few things.  

				</p>
			</aside>
		</section>

		<section data-background="#e6f7ff">
			<h3>Many such applications of LLMs</h3>
			<img height="400px" src="applications.jpeg">
			<p style="color:blue;font-size:11px;"> From Appypie</p>
			<aside class="notes">
				<p>
					Some of the other applications of LLMs are:

				</p>
			</aside>
		</section>

		<section data-background="#e6f7ff">
			<h3>Architecture of a typical LLM</h3>
			<div class="container">
				<div class="container">
					<img height="500px" src="llm_architecture.jpeg" alt="LLM Architecture">
					<div class="highlight highlight-1"></div>
					<div class="highlight highlight-2"></div>
					<!-- Add more highlight divs as needed -->
				  </div>
				  <p style="color:blue;font-size:11px;">From https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder</p>
			<aside class="notes">
				<p>
					Some of the other applications of LLMs are:
				</p>
			</aside>
			<!-- <ul>
				<li class="fragment fade-in-then-semi-out">Encoder-Decoder Transformer</li>
				<li class="fragment fade-in-then-semi-out">Tokenization</li>
				<li class="fragment fade-in-then-semi-out">Attention</li>
				<li class="fragment fade-in-then-semi-out">Text generation</li>
				
			</ul> -->
			<aside class="notes">
				<p>
					Now lets’s understand the architecture of LLMs. 
					Encoder-decoder transformer
					Encoder: Think of an encoder like someone who reads a story and takes notes on important details. In the context of a Language Model, the encoder takes a sentence or a piece of text as input and processes it to understand the key information. It's like breaking down a sentence into smaller parts and figuring out the main ideas.
					Decoder: Now, imagine a decoder as someone who uses those notes to tell a story in a different language. In the Language Model, the decoder takes the encoded information and generates a new piece of text. It's like translating the summarized notes into a different language or context.
					Summary: Together, they make sure the story is understood and shared in a new way. So, in summary, an encoder processes information, and a decoder uses that information to generate something new, forming a crucial part of how Language Models work.


					Tokenization
					Tokenization is the process of breaking down text into smaller units called tokens.
					Tokens can be words, subwords, or even characters, depending on the chosen tokenization strategy.
					This step is crucial for the model to understand and process the input text efficiently.

					Attention
					Think of a classroom where a teacher is explaining a lesson. The teacher pays attention to different students at different times based on their needs or questions. Similarly, the attention mechanism in a transformer allows the model to focus on different parts of a sentence or text, giving importance to specific words based on the context.
					Components of Attention:
					Query: Think of it as the question the student asks.
					Key: Think of it as the student who has the answer.
					Value: Think of it as the actual answer the student provides.

					Text generation 
					LLMs utilize the decoder part of the transformer architecture for text generation, sampling or selecting tokens sequentially.


				</p>
			</aside>
		</section>


		<!-- <section data-background="#e6f7ff">
			<h3>Working of LLM in production</h3>
			<img height="400px" src="working.png">
			<p style="color:blue;font-size:11px;"> From TDS</p>
			<aside class="notes">
				<p>
					
				</p>
			</aside>
		</section> -->

		<section data-background="#e6f7ff">
			<h3>Some popular LLMs</h3>
			<ul>
				<li class="fragment fade-in-then-semi-out"> BERT (Bidirectional Encoder Representations from Transformers) (by Google) </li>
				<li class="fragment fade-in-then-semi-out"> GPT (Generative Pre-trained Transformer) (by OpenAI)</li>
				<li class="fragment fade-in-then-semi-out"> LLaMA (by Meta).</li>
				
			</ul>
			<aside class="notes">
				<p>
					
				</p>
			</aside>
		</section>

		<section data-background="#e6f7ff">
			<h3>Fine tuning LLMs</h3>
			<img height="400px" src="fine_tune.png">
			<p style="color:blue;font-size:11px;"> From Medium</p>
			<aside class="notes">
				<p>
					BERT:
					BERT, developed by Google, is a cutting-edge natural language processing model that understands context by considering both preceding and following words, significantly enhancing the representation of word meanings in a bidirectional manner.
					GPT (Generative Pre-trained Transformer) (by OpenAI):
					GPT, pioneered by OpenAI, is a state-of-the-art language model that utilizes a transformer architecture, capable of generating coherent and contextually relevant text. It demonstrates powerful language understanding and generation through pre-training on diverse datasets.
					LLaMA (by Meta):
					LLaMA, developed by Meta, is an acronym for Language Model for Many Applications. Although specific details may vary, it is an initiative focused on creating versatile language models that can be applied across a broad range of tasks and applications within the Meta ecosystem.

				</p>
			</aside>
		</section>

		<section data-background="#e6f7ff">
			<h3>Fine tuning LLMs</h3>
			<ul>
				<li class="fragment fade-in-then-semi-out"> Full fine-tuning: Full fine-tuning refers to training all the parameters in the model. It is not an efficient technique, but it produces slightly better results. </li>
				<li class="fragment fade-in-then-semi-out"> LoRA: A parameter-efficient technique (PEFT) based on low-rank adapters. Instead of training all the parameters, we only train these adapters.</li>
				
			</ul>
			<aside class="notes">
				<p>
					Pre-training: Initially, a language model is trained on a massive amount of diverse and general language data. This phase helps the model learn the intricacies of language, grammar, and contextual understanding. Models like BERT, GPT, and LLaMA go through this extensive pre-training to capture a broad understanding of language.

					Fine-tuning: After pre-training, the model can be fine-tuned for specific tasks or domains. This involves training the model on a smaller, task-specific dataset. The goal is to adapt the pre-trained model to the nuances and characteristics of the target task, improving its performance on that particular application.

					Fine-tuning allows leveraging the general knowledge acquired during pre-training while tailoring the model to perform exceptionally well on targeted tasks, making LLMs versatile tools for a wide array of natural language processing applications.

					LoRA: Low Rank Adaptation of LLM 
					Helps in efficiently fine tuning LLM with lesser computation requirements. 
					Reduces the number of parameters that require fine-tuning. 

				</p>
			</aside>
		</section>

		<section>
			<h3>Open Jupyter Notebooks</h3>
			<a target="_blank" href="https://colab.research.google.com/drive/1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd?usp=sharing">
				<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
			  </a>
			<aside class="notes">
			</aside>
		</section>

		<section data-background="#e6f7ff">
			<h3>AI Literacy is not just about understanding AI functions and usage but also:  </h3>
			
			<ul>
				<li>Right Evaluation: Generalizibility and AI hallucination.</li>
				<li>Ethical considerations: Fairness, accountability, transparency, safety, etc. </li>
				
			</ul>
			
			<aside class="notes">
				<p>
					Refer to the  documentation here https://ubc-library-rc.github.io/llm/content/introduction.html 
				</p>
				
			</aside>
		</section>

		<section data-background="#e6f7ff">
			<h3>Is it safe to use chatGPT?  </h3>
			
			<img height="550px" src="https://libapps-ca.s3.amazonaws.com/customers/154/images/is-it-safe-to-use-chatgpt-for-your-task_3.png">
			<p style="color:blue;font-size:11px;"> Image by Aleksandr Tiulkanov, which is licensed under CC BY. </p>
			
			<aside class="notes">
				
			</aside>
		</section>
		

		<section data-background="#e6f7ff">
			<h3>Using LLMs for research</h3>
			<ul>
				<li class="fragment fade-in-then-semi-out"><ul> <b>Advantages/Uses</b> 
				<li>Covers multiple domains</li>
				<li>Can be used for brainstorming (wording your thoughts)</li>
				<li>Sentence formation for papers</li>
				</ul></li>

				<li class="fragment fade-in-then-semi-out"><ul> <b>Disadvantages</b> 
					<li>Lacks specificity</li>
					<li>Potential bias</li>
					<li>Lacks source</li>

				</ul></li>
			</ul>
			
			<aside class="notes">
				
			</aside>
		</section>

		<section>
			<h3>Ethics</h3>
			<img  data-src="https://ubc-library-rc.github.io/intro-machine-learning/content/images/Ethics.jpg" alt="Ethics" width="800">
			<p style="color:blue;font-size:11px;">Image from: Lepri, Bruno, Nuria Oliver, and Alex Pentland. "Ethical machines: The human-centric use of artificial intelligence." IScience 24.3 (2021): 102249.</p>

			<aside class="notes">
				
			</aside>
		</section>

		<section>
			<h3>Where to go from here?</h3>
			<ul>
				<li class="fragment fade-in-then-semi-out">Learn math, programming, and software development: <a href="https://ubc-library-rc.github.io/">Digital Scholarship workshops at UBC Library</a></li>
				<li class="fragment fade-in-then-semi-out">Online courses such as <a href="https://www.coursera.org/learn/machine-learning?specialization=machine-learning-introduction/">Supervised Machine Learning course on Coursera</a></li>
				<li class="fragment fade-in-then-semi-out">Youtube Tutorials such as <a href="https://www.youtube.com/watch?v=7eh4d6sabA0">Python Machine Learning Tutorial Series</a></li>
				<li class="fragment fade-in-then-semi-out">Find similar examples in <a href="https://scikit-learn.org/stable/auto_examples/index.html">Scikit-learn documentation</a></li>
				<li class="fragment fade-in-then-semi-out">Join communities such as <a href="https://www.kaggle.com/">Kaggle</a> or <a href="https://amscampusbase.ubc.ca/dsci/home/">AMS Data Science Club</a></li>
			</ul>
			<aside class="notes">
				
			</aside>
		</section>
	
		<section>
			<h3> Future workshops </h3>
			<table style="font-size:14px">
				<tr>
				<th> Title </th>
				<th> Series</th>
				</tr>

				<tr>
					<td> Regression models </td>
					
					<td> Tue, Mar 19, 2024 (1:00pm to 3:00pm) </td>
				</tr>

				<tr>
					<td> Classification and clustering models</td>
					
					<td> Tue, Mar 26, 2024 (1:00pm to 3:00pm)</td>
				</tr>

				<tr>
					<td> Neural networks </td>
					
					<td> Tue, Apr 2, 2024 (1:00pm to 3:00pm) </td>
				</tr>


			</table>

			<p> Register <a href="https://libcal.library.ubc.ca/calendar/vancouver?t=g&q=introduction%20to%20machine%20learning&cid=7544&cal=7544&inc=0"> here</a></p>


		</section>

    <section data-background="#002145">
       <p> More from the Research Commons at (UBC-V)</p>
       <ul>
         <li><a href="https://researchcommons.library.ubc.ca/">researchcommons.library.ubc.ca</a></li>
         <li><a href="https://researchcommons.library.ubc.ca/events/">Upcoming events</a></li>
         <li><a href="https://researchcommons.library.ubc.ca/oer/">Open Educational Resources (OERs)</a></li>
       </ul>
    </section>

    <section data-background="#002145">
        <p> And  from the Center for Scholarly Communication (UBC-O)</p>
        <ul>
          <li><a href="https://library.ok.ubc.ca/research/csc/">library.ok.ubc.ca/research/csc/</a></li>
          <li><a href="https://library.ok.ubc.ca/research/csc/workshops/">Upcoming events</a></li>
          </ul>
    </section>

   

</div>

<script src="https://ubc-library-rc.github.io/reveal-ubc/js/reveal.js"></script>

	<script>

		// More info https://github.com/hakimel/reveal.js#configuration
		Reveal.initialize({
			controls: true,
			progress: true,
			center: true,
			hash: true,

			transition: 'none', // none/fade/slide/convex/concave/zoom

		// More info https://github.com/hakimel/reveal.js#dependencies
			dependencies: [
				{ src: 'https://ubc-library-rc.github.io/reveal-ubc/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
				{ src: 'https://ubc-library-rc.github.io/reveal-ubc/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
				{ src: 'https://ubc-library-rc.github.io/reveal-ubc/plugin/highlight/highlight.js' },
				{ src: 'https://ubc-library-rc.github.io/reveal-ubc/plugin/search/search.js', async: true },
				{ src: 'https://ubc-library-rc.github.io/reveal-ubc/plugin/zoom-js/zoom.js', async: true },
				{ src: 'https://ubc-library-rc.github.io/reveal-ubc/plugin/notes/notes.js', async: true }
				]
			});

	</script>

	</body>
</html>
