---
layout: default
title: AI Literacy and Ethical AI
nav_order: 4
---
# What is AI Literacy? 

AI literacy involves more than just preparing learners for future career opportunities involving AI i.e. teaching algorithms and their usage. It's equally crucial to equip them with an understanding of the potential risks associated with AI, such as algorithmic bias and the potential for malicious use.


Different paradigms of AI literacy are: 

1. Know and understand AI: Acquiring fundamental concepts, skills, knowledge. 

2. Use and apply AI: Data analytics with AI suggestions or using chatGPT. 

3. Evaluate AI: Critically evaluate AI technologies and outcome they generate. 

4. Ethical AI: Fairness, accountability, transparency, safety, etc. 


In our ML workshops, we spent a lot of time focusing on the above points (i.e., understanding AI and using them). But when talking about Generative AI (like LLMs), some of these points related to evalution and ethics becomes even more important. 


## Evaluating AI generated content 
Do not blindly reply on the content generated. For some of the image generation model, the generated image might be far from the reality. While for some LLMs, the generated text might false. 

What do I do then?
Fact-Check. Fact-Check. Fact-Check. Check the the generated results from some the trusted sources. LLM can do a great job of putting all the information you have in flow with command on language. 

Ask LLM for citations by prompting to ask for it. Be careful, some LLMs too intelligent and might generate fake citations. 


## Ethical AI
The rapid rise in AI raise profound ethical concerns. 

1. Privacy: Everytime you use some GenAI products (like chatGPT), you are shipping off a copy of your data to the the model servers. They will use it improve their model. They might sell it to 3rd party companies for further development and research. When engaging with AI tools, it's important to exercise caution regarding sharing sensitive details such as personal, confidential, or proprietary information.

2. Bias: GenAI can amplify pre-existing biases in the data that it is trained on. Moreover, based on what people prompt as input, they might embed their own bias.  

3. Lack of Explainaibility and transparency: Do you know that LLMs are made of huge neural networks doing a lot of processing. Neural networks are known to be black box, meaning it is difficult to understand how deep neural networks make their decisions. 


## Read more at

1. UNESCO Ethics of AI: https://www.unesco.org/en/artificial-intelligence/recommendation-ethics

2. Conceptualizing AI Literacy: https://go.exlibris.link/fFY0XLFX 



