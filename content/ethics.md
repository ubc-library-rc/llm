---
layout: default
title: AI Literacy and Ethical AI
nav_order: 7
---
# What is AI Literacy? 

AI literacy involves more than just preparing learners for future careers involving AI, such as teaching algorithms and their usage. It is equally crucial to equip them with an understanding of the potential risks associated with AI, such as algorithmic bias and the potential for malicious use.

Different paradigms of AI literacy include:

1. **Know and Understand AI:** Acquiring fundamental concepts, skills, and knowledge.
2. **Use and Apply AI:** Utilizing data analytics with AI suggestions or using tools like ChatGPT.
3. **Evaluate AI:** Critically evaluating AI technologies and the outcomes they generate.
4. **Ethical AI:** Addressing fairness, accountability, transparency, safety, etc.

In our ML workshops, we focus extensively on understanding AI and using it. However, when discussing Generative AI (such as LLMs), the aspects of evaluation and ethics become even more critical.

## Evaluating AI-Generated Content

Do not blindly rely on the content generated by AI. For some image generation models, the results might be far from reality. Similarly, with some LLMs, the generated text might be inaccurate.

What should you do?  
**Fact-Check. Fact-Check. Fact-Check.** Verify the generated results using trusted sources. While LLMs can effectively synthesize information and present it coherently, always ask for citations and be cautious, as some LLMs might generate fake citations.

## Ethical AI

The rapid rise in AI raises profound ethical concerns:

1. **Privacy:** Every time you use Generative AI products (like ChatGPT), you are sending a copy of your data to the model servers. This data may be used to improve the model or potentially sold to third-party companies for further development and research. When engaging with AI tools, exercise caution about sharing sensitive personal, confidential, or proprietary information.

2. **Bias:** Generative AI can amplify pre-existing biases present in the training data. Additionally, the biases of those who provide input prompts may be reflected in the AI's outputs.

3. **Lack of Explainability and Transparency:** LLMs are built on complex neural networks that perform extensive processing. Neural networks are often considered "black boxes," making it difficult to understand how deep neural networks make their decisions.

## Read More At

1. [UNESCO Ethics of AI](https://www.unesco.org/en/artificial-intelligence/recommendation-ethics)
2. [Conceptualizing AI Literacy](https://go.exlibris.link/fFY0XLFX)

---

**Q1:** What are some effective methods for teaching AI literacy to students?

**Q2:** How can educators incorporate ethical considerations into AI curriculum?

**Q3:** What are the challenges in ensuring transparency in AI technologies?